{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('heart.csv')\n",
    "raw_data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['sex', 'fbs', 'exang']:\n",
    "    positive = '{}_1'.format(feature)\n",
    "    negative = '{}_0'.format(feature)\n",
    "    data[positive] = 0\n",
    "    data[positive][data[feature] == 1] = 1\n",
    "    data[negative] = 0\n",
    "    data[negative][data[feature] == 0] = 1\n",
    "    data = data.drop([feature], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['cp', 'restecg', 'slope', 'ca', 'thal']:\n",
    "    values = {x for x in data[feature]}\n",
    "    for value in values:\n",
    "        column_name = '{}_{}'.format(feature, value)\n",
    "        data[column_name] = 0\n",
    "        data[column_name][data[feature] == value] = 1\n",
    "    data = data.drop([feature], axis='columns')\n",
    "    \n",
    "numerical_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKETS = 6\n",
    "NUMERICAL_FEATURES = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "for feature in NUMERICAL_FEATURES:\n",
    "    bins = sorted({x for x in pd.cut(data[feature], BUCKETS)})\n",
    "    for bucket in range(len(bins)):\n",
    "        column_name = '{}_{}'.format(feature, bucket+1)\n",
    "        data[column_name] = 0\n",
    "        data[column_name][(data[feature] > bins[bucket].left) & (data[feature] <= bins[bucket].right)] = 1\n",
    "        \n",
    "data = data.drop(NUMERICAL_FEATURES, axis='columns')\n",
    "data = data[[x for x in data.columns if x != 'target'] + ['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pos_neg(samples):\n",
    "    return samples[samples[:, -1] == 1][:, :-1], samples[samples[:, -1] == 0][:, :-1]\n",
    "\n",
    "def get_splits(data, seed=1):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    SPLITS = 5\n",
    "    split_size = data.shape[0] // SPLITS\n",
    "    print('positive: {}, negative: {}, ratio: {:.2f}'.format(\n",
    "        data[data['target'] == 1].shape[0],\n",
    "        data[data['target'] == 0].shape[0],\n",
    "        data[data['target'] == 1].shape[0] / data[data['target'] == 0].shape[0],\n",
    "    ))\n",
    "    samples = data.to_numpy().astype('int64')\n",
    "    np.random.shuffle(samples)\n",
    "    splits = []\n",
    "    for i in range(SPLITS):\n",
    "        train = np.concatenate([samples[:i*split_size], samples[(i+1)*split_size:]], axis=0)\n",
    "        test = samples[i*split_size:(i+1)*split_size]\n",
    "        splits.append([train, test])\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsComputer:\n",
    "    def __init__(self, algo_name):\n",
    "        self.algo_name = algo_name\n",
    "        self.runs = 0\n",
    "        self.tp = 0\n",
    "        self.fn = 0\n",
    "        self.tn = 0\n",
    "        self.fp = 0\n",
    "        self.tpr = 0\n",
    "        self.tnr = 0\n",
    "        self.fpr = 0\n",
    "        self.fnr = 0\n",
    "        self.fdr = 0\n",
    "        self.accuracy = 0\n",
    "        self.negative_predictive_value = 0\n",
    "        self.precision = 0\n",
    "        self.recall = 0\n",
    "        \n",
    "    def update(self, tp, fn, tn, fp):\n",
    "        self.runs += 1\n",
    "        self.tp += tp\n",
    "        self.fn += fn\n",
    "        self.tn += tn\n",
    "        self.fp += fp\n",
    "        total = tp + fn + tn + fp\n",
    "        self.tpr += tp / total\n",
    "        self.tnr += tn / total\n",
    "        self.fpr += fp / total\n",
    "        self.fnr += fn / total\n",
    "        if (tp + fp > 0) and self.fdr is not None:\n",
    "            self.fdr += fp / (tp + fp)\n",
    "        else:\n",
    "            self.fdr = None\n",
    "        self.accuracy += (tp + tn) / total\n",
    "        self.negative_predictive_value += tn / (tn + fn)\n",
    "        if (tp + fp > 0) and self.precision is not None:\n",
    "            self.precision += tp / (tp + fp)\n",
    "        else:\n",
    "            self.precision = None\n",
    "        self.recall += tp / (tp + fn)\n",
    "        \n",
    "    def describe(self):\n",
    "        print('====== ' + self.algo_name + ' ======')\n",
    "        print('TOTAL RUNS:', self.runs)\n",
    "        print('TRUE POSITIVE:', self.tp / self.runs)\n",
    "        print('TRUE NEGATIVE:', self.tn / self.runs)\n",
    "        print('FALSE POSITIVE:', self.fp / self.runs)\n",
    "        print('FALSE NEGATIVE:', self.fn / self.runs)\n",
    "        print('TRUE POSITIVE RATE:', round(self.tpr / self.runs, 3))\n",
    "        print('TRUE NEGATIVE RATE:', round(self.tnr / self.runs, 3))\n",
    "        print('FALSE POSITIVE RATE:', round(self.fpr / self.runs, 3))\n",
    "        print('FALSE NEGATIVE RATE:', round(self.fnr / self.runs, 3))\n",
    "        print('NEGATIVE PREDICTIVE VALUE:', round(self.negative_predictive_value / self.runs, 3))\n",
    "        print('FALSE DISCOVERY RATE:', (round(self.fdr / self.runs, 3)) if self.fdr is not None else '<NOT_DEFINED>')\n",
    "        print('ACCURACY:', round(self.accuracy / self.runs, 3))\n",
    "        print('PRECISION:', round(self.precision / self.runs, 3) if self.precision is not None else '<NOT_DEFINED>')\n",
    "        print('RECALL:', round(self.recall / self.runs, 3))\n",
    "        print('=======' + '='*len(self.algo_name) + '=======')\n",
    "        \n",
    "    def get_value(self, value_name):\n",
    "        if value_name in ['runs', 'algo_name']:\n",
    "            return getattr(self, value_name)\n",
    "        else:\n",
    "            value = getattr(self, value_name)\n",
    "            if value is None:\n",
    "                return None\n",
    "            return value / self.runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: 165, negative: 138, ratio: 1.20\n"
     ]
    }
   ],
   "source": [
    "numerical_splits = get_splits(numerical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Random Forest (with numerical features) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 22.8\n",
      "TRUE NEGATIVE: 35.8\n",
      "FALSE POSITIVE: 1.2\n",
      "FALSE NEGATIVE: 0.2\n",
      "TRUE POSITIVE RATE: 0.38\n",
      "TRUE NEGATIVE RATE: 0.597\n",
      "FALSE POSITIVE RATE: 0.02\n",
      "FALSE NEGATIVE RATE: 0.003\n",
      "NEGATIVE PREDICTIVE VALUE: 0.994\n",
      "FALSE DISCOVERY RATE: 0.054\n",
      "ACCURACY: 0.977\n",
      "PRECISION: 0.946\n",
      "RECALL: 0.993\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "metrics = MetricsComputer('Random Forest (with numerical features)')\n",
    "for train, test in numerical_splits:\n",
    "    pos_train, neg_train = split_pos_neg(train)\n",
    "    pos_test, neg_test = split_pos_neg(test)\n",
    "    X = np.concatenate([pos_train, neg_train])\n",
    "    Y = np.concatenate([np.ones(shape=(pos_train.shape[0],)), np.zeros(shape=(neg_train.shape[0],))])\n",
    "    clf = RandomForestClassifier(n_estimators=50, max_depth=10)\n",
    "    clf = clf.fit(X, Y)\n",
    "    metrics.update(\n",
    "        tp=int(clf.predict(pos_test).sum()),\n",
    "        fn=int((1 - clf.predict(pos_test)).sum()),\n",
    "        tn=int((1 - clf.predict(neg_test)).sum()),\n",
    "        fp=int(clf.predict(neg_test).sum()),\n",
    "    )\n",
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== LogReg (with numerical features) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 23.0\n",
      "TRUE NEGATIVE: 36.4\n",
      "FALSE POSITIVE: 0.6\n",
      "FALSE NEGATIVE: 0.0\n",
      "TRUE POSITIVE RATE: 0.383\n",
      "TRUE NEGATIVE RATE: 0.607\n",
      "FALSE POSITIVE RATE: 0.01\n",
      "FALSE NEGATIVE RATE: 0.0\n",
      "NEGATIVE PREDICTIVE VALUE: 1.0\n",
      "FALSE DISCOVERY RATE: 0.028\n",
      "ACCURACY: 0.99\n",
      "PRECISION: 0.972\n",
      "RECALL: 1.0\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "metrics = MetricsComputer('LogReg (with numerical features)')\n",
    "for train, test in numerical_splits:\n",
    "    pos_train, neg_train = split_pos_neg(train)\n",
    "    pos_test, neg_test = split_pos_neg(test)\n",
    "    X = np.concatenate([pos_train, neg_train])\n",
    "    Y = np.concatenate([np.ones(shape=(pos_train.shape[0],)), np.zeros(shape=(neg_train.shape[0],))])\n",
    "    clf = LogisticRegression(random_state=1)\n",
    "    clf = clf.fit(X, Y)\n",
    "    metrics.update(\n",
    "        tp=int(clf.predict(pos_test).sum()),\n",
    "        fn=int((1 - clf.predict(pos_test)).sum()),\n",
    "        tn=int((1 - clf.predict(neg_test)).sum()),\n",
    "        fp=int(clf.predict(neg_test).sum()),\n",
    "    )\n",
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: 165, negative: 138, ratio: 1.20\n"
     ]
    }
   ],
   "source": [
    "splits = get_splits(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Random Forest (with binarized features) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 27.8\n",
      "TRUE NEGATIVE: 21.2\n",
      "FALSE POSITIVE: 6.2\n",
      "FALSE NEGATIVE: 4.8\n",
      "TRUE POSITIVE RATE: 0.463\n",
      "TRUE NEGATIVE RATE: 0.353\n",
      "FALSE POSITIVE RATE: 0.103\n",
      "FALSE NEGATIVE RATE: 0.08\n",
      "NEGATIVE PREDICTIVE VALUE: 0.819\n",
      "FALSE DISCOVERY RATE: 0.184\n",
      "ACCURACY: 0.817\n",
      "PRECISION: 0.816\n",
      "RECALL: 0.851\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "metrics = MetricsComputer('Random Forest (with binarized features)')\n",
    "for train, test in splits:\n",
    "    pos_train, neg_train = split_pos_neg(train)\n",
    "    pos_test, neg_test = split_pos_neg(test)\n",
    "    X = np.concatenate([pos_train, neg_train])\n",
    "    Y = np.concatenate([np.ones(shape=(pos_train.shape[0],)), np.zeros(shape=(neg_train.shape[0],))])\n",
    "    clf = RandomForestClassifier(n_estimators=50, max_depth=10)\n",
    "    clf = clf.fit(X, Y)\n",
    "    metrics.update(\n",
    "        tp=int(clf.predict(pos_test).sum()),\n",
    "        fn=int((1 - clf.predict(pos_test)).sum()),\n",
    "        tn=int((1 - clf.predict(neg_test)).sum()),\n",
    "        fp=int(clf.predict(neg_test).sum()),\n",
    "    )\n",
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== LogReg (with binarized features) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 27.4\n",
      "TRUE NEGATIVE: 21.2\n",
      "FALSE POSITIVE: 6.2\n",
      "FALSE NEGATIVE: 5.2\n",
      "TRUE POSITIVE RATE: 0.457\n",
      "TRUE NEGATIVE RATE: 0.353\n",
      "FALSE POSITIVE RATE: 0.103\n",
      "FALSE NEGATIVE RATE: 0.087\n",
      "NEGATIVE PREDICTIVE VALUE: 0.807\n",
      "FALSE DISCOVERY RATE: 0.184\n",
      "ACCURACY: 0.81\n",
      "PRECISION: 0.816\n",
      "RECALL: 0.841\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "metrics = MetricsComputer('LogReg (with binarized features)')\n",
    "for train, test in splits:\n",
    "    pos_train, neg_train = split_pos_neg(train)\n",
    "    pos_test, neg_test = split_pos_neg(test)\n",
    "    X = np.concatenate([pos_train, neg_train])\n",
    "    Y = np.concatenate([np.ones(shape=(pos_train.shape[0],)), np.zeros(shape=(neg_train.shape[0],))])\n",
    "    clf = LogisticRegression(random_state=1)\n",
    "    clf = clf.fit(X, Y)\n",
    "    metrics.update(\n",
    "        tp=int(clf.predict(pos_test).sum()),\n",
    "        fn=int((1 - clf.predict(pos_test)).sum()),\n",
    "        tn=int((1 - clf.predict(neg_test)).sum()),\n",
    "        fp=int(clf.predict(neg_test).sum()),\n",
    "    )\n",
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom FCA algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Simple FCA (t=0.9) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 31.8\n",
      "TRUE NEGATIVE: 17.0\n",
      "FALSE POSITIVE: 10.4\n",
      "FALSE NEGATIVE: 0.8\n",
      "TRUE POSITIVE RATE: 0.53\n",
      "TRUE NEGATIVE RATE: 0.283\n",
      "FALSE POSITIVE RATE: 0.173\n",
      "FALSE NEGATIVE RATE: 0.013\n",
      "NEGATIVE PREDICTIVE VALUE: 0.958\n",
      "FALSE DISCOVERY RATE: 0.248\n",
      "ACCURACY: 0.813\n",
      "PRECISION: 0.752\n",
      "RECALL: 0.974\n",
      "================================\n",
      "====== Simple FCA (t=1.05) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 27.6\n",
      "TRUE NEGATIVE: 22.2\n",
      "FALSE POSITIVE: 5.2\n",
      "FALSE NEGATIVE: 5.0\n",
      "TRUE POSITIVE RATE: 0.46\n",
      "TRUE NEGATIVE RATE: 0.37\n",
      "FALSE POSITIVE RATE: 0.087\n",
      "FALSE NEGATIVE RATE: 0.083\n",
      "NEGATIVE PREDICTIVE VALUE: 0.824\n",
      "FALSE DISCOVERY RATE: 0.163\n",
      "ACCURACY: 0.83\n",
      "PRECISION: 0.837\n",
      "RECALL: 0.845\n",
      "=================================\n",
      "====== Simple FCA (t=1.2) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 22.4\n",
      "TRUE NEGATIVE: 24.8\n",
      "FALSE POSITIVE: 2.6\n",
      "FALSE NEGATIVE: 10.2\n",
      "TRUE POSITIVE RATE: 0.373\n",
      "TRUE NEGATIVE RATE: 0.413\n",
      "FALSE POSITIVE RATE: 0.043\n",
      "FALSE NEGATIVE RATE: 0.17\n",
      "NEGATIVE PREDICTIVE VALUE: 0.708\n",
      "FALSE DISCOVERY RATE: 0.105\n",
      "ACCURACY: 0.787\n",
      "PRECISION: 0.895\n",
      "RECALL: 0.686\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "def f_pos(sample, our_class, contestant_class):\n",
    "    f_sum = 0\n",
    "    for our_sample in our_class:\n",
    "        intersection = sample * our_sample\n",
    "        f_sum += (intersection.sum() / our_class.shape[0])\n",
    "    return f_sum \n",
    "\n",
    "for COEF in [0.9, 1.05, 1.2]:\n",
    "    metrics = MetricsComputer('Simple FCA (t={})'.format(COEF))\n",
    "    for train, test in splits:\n",
    "        pos_train, neg_train = split_pos_neg(train)\n",
    "        pos_test, neg_test = split_pos_neg(test)\n",
    "        pos_goods = 0\n",
    "        pos_bads = 0\n",
    "        for sample in pos_test:\n",
    "            pos = f_pos(sample, pos_train, neg_train)\n",
    "            neg = f_pos(sample, neg_train, pos_train)\n",
    "            if pos / neg >= COEF:\n",
    "                pos_goods += 1\n",
    "            else:\n",
    "                pos_bads += 1\n",
    "\n",
    "        neg_goods = 0\n",
    "        neg_bads = 0\n",
    "        for sample in neg_test:\n",
    "            pos = f_pos(sample, pos_train, neg_train)\n",
    "            neg = f_pos(sample, neg_train, pos_train)\n",
    "            if pos / neg < COEF:\n",
    "                neg_goods += 1\n",
    "            else:\n",
    "                neg_bads += 1\n",
    "\n",
    "        metrics.update(pos_goods, pos_bads, neg_goods, neg_bads)\n",
    "\n",
    "    metrics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Complex FCA (t=0.75) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 31.4\n",
      "TRUE NEGATIVE: 17.8\n",
      "FALSE POSITIVE: 9.6\n",
      "FALSE NEGATIVE: 1.2\n",
      "TRUE POSITIVE RATE: 0.523\n",
      "TRUE NEGATIVE RATE: 0.297\n",
      "FALSE POSITIVE RATE: 0.16\n",
      "FALSE NEGATIVE RATE: 0.02\n",
      "NEGATIVE PREDICTIVE VALUE: 0.94\n",
      "FALSE DISCOVERY RATE: 0.236\n",
      "ACCURACY: 0.82\n",
      "PRECISION: 0.764\n",
      "RECALL: 0.962\n",
      "==================================\n",
      "====== Complex FCA (t=0.9) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 28.2\n",
      "TRUE NEGATIVE: 22.4\n",
      "FALSE POSITIVE: 5.0\n",
      "FALSE NEGATIVE: 4.4\n",
      "TRUE POSITIVE RATE: 0.47\n",
      "TRUE NEGATIVE RATE: 0.373\n",
      "FALSE POSITIVE RATE: 0.083\n",
      "FALSE NEGATIVE RATE: 0.073\n",
      "NEGATIVE PREDICTIVE VALUE: 0.844\n",
      "FALSE DISCOVERY RATE: 0.152\n",
      "ACCURACY: 0.843\n",
      "PRECISION: 0.848\n",
      "RECALL: 0.862\n",
      "=================================\n",
      "====== Complex FCA (t=1.05) ======\n",
      "TOTAL RUNS: 5\n",
      "TRUE POSITIVE: 25.0\n",
      "TRUE NEGATIVE: 23.6\n",
      "FALSE POSITIVE: 3.8\n",
      "FALSE NEGATIVE: 7.6\n",
      "TRUE POSITIVE RATE: 0.417\n",
      "TRUE NEGATIVE RATE: 0.393\n",
      "FALSE POSITIVE RATE: 0.063\n",
      "FALSE NEGATIVE RATE: 0.127\n",
      "NEGATIVE PREDICTIVE VALUE: 0.761\n",
      "FALSE DISCOVERY RATE: 0.135\n",
      "ACCURACY: 0.81\n",
      "PRECISION: 0.865\n",
      "RECALL: 0.761\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "A_DEG = 50\n",
    "B_DEG = 2.5\n",
    "\n",
    "def f_pos(sample, our_class, contestant_class):\n",
    "    f_sum = 0\n",
    "    for our_sample in our_class:\n",
    "        intersection = sample * our_sample\n",
    "        upper = 2 ** (intersection.sum() * A_DEG / our_class.shape[0])\n",
    "        counterexamples = np.all((contestant_class - intersection) >= 0, axis=1).sum()\n",
    "        lower = 2 ** (counterexamples*B_DEG / contestant_class.shape[0])\n",
    "        f_sum += upper / lower\n",
    "    return f_sum \n",
    "\n",
    "for COEF in [0.75, 0.9, 1.05]:\n",
    "    metrics = MetricsComputer('Complex FCA (t={})'.format(COEF))\n",
    "\n",
    "    for train, test in splits:\n",
    "        pos_train, neg_train = split_pos_neg(train)\n",
    "        pos_test, neg_test = split_pos_neg(test)\n",
    "        pos_goods = 0\n",
    "        pos_bads = 0\n",
    "        for sample in pos_test:\n",
    "            pos = f_pos(sample, pos_train, neg_train)\n",
    "            neg = f_pos(sample, neg_train, pos_train)\n",
    "            if pos / neg >= COEF:\n",
    "                pos_goods += 1\n",
    "            else:\n",
    "                pos_bads += 1\n",
    "\n",
    "        neg_goods = 0\n",
    "        neg_bads = 0\n",
    "        for sample in neg_test:\n",
    "            pos = f_pos(sample, pos_train, neg_train)\n",
    "            neg = f_pos(sample, neg_train, pos_train)\n",
    "            if pos / neg < COEF:\n",
    "                neg_goods += 1\n",
    "            else:\n",
    "                neg_bads += 1\n",
    "\n",
    "        metrics.update(pos_goods, pos_bads, neg_goods, neg_bads)\n",
    "\n",
    "    metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
